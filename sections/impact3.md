[<<< Previous](impact2.md) | [Next >>>](range.md)

# Level of Impact III: Social, Political, and Economic Impacts of Projects or Research  

## Social, political, and economic impacts

> "At a third level of impact, we can consider **the social, economic, or political changes caused** by one’s research processes or products, in both the short and long term." ([Annette Markham, "OKCupid data release fiasco: It’s time to rethink ethics education," 2016](http://annettemarkham.com/2016/05/okcupid-data-release-fiasco-its-time-to-rethink-ethics-education/), emphasis added)  

Some questions to consider:

- Whose **labor** and what **materials** are used to make the digital tools you use? How should we (those who benefit from the labor of other people) attribute others' labor? How can we (users of these tools) be held accountable?  

> "the energy demands for digital daily life, a key source of big data for social science research, are significant in this era of climate change ... should researchers take the lead in asking cloud storage providers and data processing centers to shift to sustainable and renewable energy sources?" ([Matthew Zook et al, "Ten simple rules for responsible big data research," 2017](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005399))  

* Could your research or project be used to justify or facilitate potentially harmful **control** or **surveillance**?    

> "'Lots of proprietary programs spy. Windows spies, Mac OS spies, iOS spies, Flash player spies. Thousands of apps spy on the user' ... The internet of things—well I call it the internet of stings—it's a way that those companies can get power over more things in your life, snoop on more things in your life and have total power... 'Portable phones, every portable phone has a universal backdoor… And with the backdoor [the phone company] can convert it into a full-time listening device that can hear all the conversation in the room, even when it's not making any call, even when it’s supposed to be switched off.'" ([Factor, interview with Richard Stallman, "The Vanishing State of Privacy," 2017](http://magazine.factor-tech.com/factor_winter_2017/richard_stallman_and_the_vanishing_state_of_privacy))  

> [Even more so now] "In a post 9/11 world, the U. S. government utilizes computer technology to exert some degree of control over its citizens, rather than protect their privacy... [Also,] internet software can be used as parasocietal mechanisms for the observation of online interactions. Online social networks allow for high levels of surveillance. In addition to marketers, college officials and parents can access social networking sites. Students may think that their Facebook or MySpace journal entries are private but they are actually public diaries." ([Susan Barnes, “A Privacy Paradox,” 2006](http://firstmonday.org/article/view/1394/1312))   

> "Other cases show that 'public' datasets are easily adapted for highly invasive research by incorporating other data, such as Hague et al.’s use of property records and geographic profiling techniques to allegedly identify the pseudonymous artist Banksy" ([Matthew Zook et al, "Ten simple rules for responsible big data research," 2017](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005399))  

* Could it influence **social or political discourse**? Modes of **profit**?

> "to what extent is a research project focused on enhancing the public good or the underserved of society? Are questions about equity or promoting other public values being addressed in one’s data streams, or is a big data focus rendering them invisible or irrelevant to your analysis [37]? How can increasingly vulnerable yet fundamentally important public resources—such as state-mandated cancer registries—be protected? How might research aid or inhibit different business and political actors?" ([Matthew Zook, et al, "Ten simple rules for responsible big data research," 2017](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005399))  

These are *big* questions.  

A researcher should not be expected to have all the answers or predict the future. The aim here is to thoughtfully consider these questions, to think critically about potential positive and negative effects of research and projects, and to be responsible and accountable.  

As Annette Markham reminds us, as discussed earlier in this session:  

> "an impact approach is targeted toward the possible or probable impact, rather than the prevention of impact in the first place. It acknowledges that we change the world as we conduct even the smallest of scientific studies, and therefore, we must take some personal responsibility for our methods." ([Annette Markham, "OKCupid data release fiasco: It’s time to rethink ethics education," 2016](http://annettemarkham.com/2016/05/okcupid-data-release-fiasco-its-time-to-rethink-ethics-education/))  

![close-up photo of a drop of water falling into a pool of water, creating a series of concentric ripples](../images/ripple.jpg)  
Image source: [Sergiu Bacioiu from Romania, "Ripple effect on water," Wikimedia, Creative Commons Attribution 2.0 Generic license](https://commons.wikimedia.org/wiki/File:Ripple_effect_on_water.jpg)  

Further readings:  
[Xiang Biao, *Global Body Shopping: An Indian Labor System in the Information Technology Industry*, 2007](https://press.princeton.edu/titles/8315.html)  
[Elsa Davidson, *The Burdens of Aspiration: Schools, Youth, and Success in the Divided Social Worlds of Silicon Valley*, 2011](https://nyupress.org/books/9780814720875/)  
[Anna Lauren Hoffmann, "Data Violence and How Bad Engineering Choices Can Damage Society," 2018](https://medium.com/s/story/data-violence-and-how-bad-engineering-choices-can-damage-society-39e44150e1d4)  
[The Policing in Chicago Research Group, "Tracked and Targeted: Early Findings on Chicago's Gang Database," 2018](http://erasethedatabase.com/wp-content/uploads/2018/02/Tracked-Targeted-0217.pdf)  
[Safiya Umoja Noble, *Algorithms of Oppression: How Search Engines Reinforce Racism*, 2018](https://nyupress.org/books/9781479837243/)  
[Cathy O'Neil, *Methods of Math Destruction: How Big Data Increases Inequality and Threatens Democracy*, 2016](https://weaponsofmathdestructionbook.com/)  
[Matthew Zook et al, "Ten simple rules for responsible big data research," 2017](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005399)  

## Activity   

Think about the digital project or research you are or will be working on. Pair up with another person near you and discuss:  

* Whose labor and what materials do you rely upon to do your work?  
* Could your research or project be used to justify or facilitate potentially harmful control or surveillance-by e.g. the state, a vigilante group, an abusive partner?  
* How could your work cause changes to or justify social, economic or political discourses?  
* Will your work be used for profit, for who?  

Share as a class. 

## Some Considerations
We cannot control how others will use our work, but we can do our best to present results in a way that cannot be misinterpreted, and make sure that our work is accessible to groups that are historically disadvantaged, subjected to biased categorization, and excluded from knowledge production. 
There are a many ways to put this into practice:
* Before you start your research, state your goals and the way you hope your work will have an impact and consider the ways your findings could be used to perpetuate stereotypes and injustice
* In your results/presentation, explicitly say the implications of your work and how your results should be used
* If you have the ability to do so, consider disseminating your project not just in academic settings, making your work known to broader audiences and stakeholders you want to use your findings
* If appropriate, make your data publicly available for others to use
* Incorporate members of these groups into your research process/team if possible
* If you use labor of individuals outside of your department or university, do your best to compensate them financially and formally acknowledge them



[<<< Previous](impact2.md) | [Next >>>](range.md)
