[<<< Previous](impact1.md) | [Next >>>](impact2.md)

# Level of Impact I, continued

## “Public” Data

Some questions to consider:  

> "In an age of digital media, do we really have any privacy?" ([Susan Barnes, “A Privacy Paradox,” 2006](http://firstmonday.org/article/view/1394/1312))  

- How do we delineate between "research" vs. "spying"?  Does this change when the project focuses on "big data"? (see [Berendt, Büchler, & Rockwell, “Is it Research or is it Spying? Thinking-Through Ethics in Big Data AI and Other Knowledge Sciences,” 2015](https://people.cs.kuleuven.be/~bettina.berendt/Papers/berendt_buechler_rockwell_KUIN_2015.pdf))
- What forms of "public" data are ethical to use? Or require attribution?
- How might we (intentionally or inadvertently) share data?

For those doing work with big data, recommended reading: [Matthew Zook et al., "Ten simple rules for responsible big data research," 2017](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005399)  

## The Question of Personhood

Some questions to consider:  

> "Is an avatar a person?"  
> "Is one’s digital information [e.g. photos, videos, audio, social media posts] an extension of the self?"  
> "Can we assume a person is wholly removed from large data pools?" *Note: "there is considerable evidence that even ‘anonymised’ datasets that contain enough personal information can result in individuals being identifiable"*  
> "Does the connection between one’s online data and [their] physical person enable psychological, economic, or physical, harm?"     

Source: [the 2012 Ethical Decision-Making and Internet Research report by the the AoIR Ethics Working Committee](http://aoir.org/reports/ethics2.pdf)  

## Considerations of Representation
* Your research question
   * How we talk about “fixing problems” in communities, cultures and people groups
   * Traditionally researchers use a deficit-focus rather than an asset-focus
* the sensitivity of certain topics (for example, illegal activities, immigration status, or abuse)
   * Ask: even though this data is available to me, would the people this data comes from want it used this way?
* Is this data representative?
   * Algorithms make their own assumptions and may classify people incorrectly (see ["Facebook Algorithms and Personal Data"](https://www.pewinternet.org/2019/01/16/facebook-algorithms-and-personal-data/))

## Activity  

Let's analyze and discuss a case study.  

Review Joshua Tabak and Vivian Zayas's [academic article](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0036671) and [their summary of it for the New York Times](http://www.nytimes.com/2012/06/03/opinion/sunday/the-science-of-gaydar.html), and discuss:

* What kinds of “human subjects” are involved in this study?
* Is a social media photo of oneself an extension of the self? 
* Does their methodology raise any ethical concerns?

Discuss with your table, then share as a group.  

Further reading: [Patrick Sweeney, "Images of Faces Gleaned from Social Media in Social Psychological Research on Sexual Orientation," 2017](https://www.academia.edu/34001772/Images_of_Faces_Gleaned_from_Social_Media_in_Social_Psychological_Research_on_Sexual_Orientation)  

[<<< Previous](impact1.md) | [Next >>>](impact2.md)
